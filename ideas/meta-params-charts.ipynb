{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# visualize histograms\n",
    "plt.figure(figsize=(40, 30)) # width and height of the plot\n",
    "legends = []\n",
    "for name, values in out_values.items(): # note: exclude the output value\n",
    "    if name != \"Softmax\":\n",
    "        t = values\n",
    "        print(f'{name}: mean {t.mean()}, std {t.std()}')\n",
    "        hy, hx = torch.histogram(t, density=True)\n",
    "        plt.plot(hx[:-1].detach(), hy.detach())\n",
    "        legends.append(f'layer ({name}')\n",
    "plt.legend(legends)\n",
    "plt.title('gradient distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "legends = []\n",
    "i = 0\n",
    "for name, p in model.named_parameters():\n",
    "    plt.plot([ud[j][i] for j in range(len(ud))])\n",
    "    legends.append(name)\n",
    "    i += 1\n",
    "plt.plot([0, len(ud)], [-3, -3], 'k') # these ratios should be ~1e-3, indicate on plot\n",
    "plt.legend(legends);"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import re\n",
    "# visualize histograms\n",
    "plt.figure(figsize=(40, 20)) # width and height of the plot\n",
    "legends = []\n",
    "for name, params in model.named_parameters():\n",
    "    if not re.search('bias', name):\n",
    "        t = params.grad\n",
    "        print(f'layer {name}: weight {tuple(params.shape)} | mean {t.mean()} | std {t.std()} | grad:data ratio { t.std() / params.std()}')\n",
    "        hy, hx = torch.histogram(t, density=True)\n",
    "        plt.plot(hx[:-1].detach(), hy.detach())\n",
    "        legends.append(f'{name} {tuple(params.shape)}')\n",
    "plt.legend(legends)\n",
    "plt.title('weights gradient distribution');"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import re\n",
    "# visualize histograms\n",
    "plt.figure(figsize=(20, 10)) # width and height of the plot\n",
    "legends = []\n",
    "for name, params in model.named_parameters():\n",
    "    if not re.search('bias', name) and not re.search('norm', name):\n",
    "        t = params\n",
    "        print(f'layer {name}: weight {tuple(params.shape)} | mean {t.mean()} | std {t.std()} | weight:data ratio { t.std() / params.std()}')\n",
    "        hy, hx = torch.histogram(t, density=True)\n",
    "        plt.plot(hx[:-1].detach(), hy.detach())\n",
    "        legends.append(f'{name} {tuple(params.shape)}')\n",
    "plt.legend(legends)\n",
    "plt.title('weights distribution');"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
