{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import sys\n",
    "import random\n",
    "\n",
    "import mne\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import math\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "import importlib\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
    "%matplotlib inline"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from modules.BciDataHandler import BciDataHandler\n",
    "\n",
    "data_handler = BciDataHandler()\n",
    "data_handler.instantiate_dataset()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ------------------------------ bci competition dataset ------------------------------\n",
    "all_subject_epochs = mne.concatenate_epochs(list(data_handler.subjects_epochs.values()))\n",
    "all_labels = all_subject_epochs.events[:, -1] - 2\n",
    "\n",
    "epochs = data_handler.subjects_epochs[1]\n",
    "labels = np.array(data_handler.subjects_labels[1]) - 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# -------------------------------- ufjf dataset --------------------------------------\n",
    "from modules.EdfHandler import EdfHandler\n",
    "\n",
    "epochs, labels = EdfHandler.getAllData([\"C:\\\\Users\\\\davi2\\Desktop\\\\bci\\\\datasets_ufjf\\\\bci\\\\001.edf\"])\n",
    "epochs = epochs[0]\n",
    "labels = np.array(labels[0])\n",
    "labels[labels == 6] = 0"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "labels"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import mne\n",
    "from mne import Epochs, pick_types, events_from_annotations\n",
    "from mne.channels import make_standard_montage\n",
    "from mne.io import concatenate_raws, read_raw_edf\n",
    "from mne.datasets import eegbci\n",
    "\n",
    "\n",
    "# #############################################################################\n",
    "# # Set parameters and read data\n",
    "\n",
    "# avoid classification of evoked responses by using epochs that start 1s after\n",
    "# cue onset.\n",
    "tmin, tmax = -1., 4.\n",
    "event_id = dict(handsOrLeft=2, feetOrRight=3)\n",
    "\n",
    "def get_physionet_data(subject, runs):\n",
    "\n",
    "    raw_fnames = eegbci.load_data(subject, runs)\n",
    "    raw = concatenate_raws([read_raw_edf(f, preload=True) for f in raw_fnames])\n",
    "    eegbci.standardize(raw)  # set channel names\n",
    "    montage = make_standard_montage('standard_1005')\n",
    "    raw.set_montage(montage)\n",
    "\n",
    "    # Apply band-pass filter\n",
    "    raw.filter(7., 30., fir_design='firwin', skip_by_annotation='edge')\n",
    "\n",
    "    events, _ = events_from_annotations(raw)\n",
    "\n",
    "    picks = pick_types(raw.info, meg=False, eeg=True, stim=False, eog=False,\n",
    "                       exclude='bads')\n",
    "\n",
    "    # Read epochs (train will be done only between 1 and 2s)\n",
    "    # Testing will be done with a running classifier\n",
    "    epochs = Epochs(raw, events, event_id, tmin, tmax, proj=True, picks=picks,\n",
    "                    baseline=None, preload=True)\n",
    "\n",
    "    epochs_data = epochs.copy().crop(tmin=1., tmax=2.)\n",
    "\n",
    "    labels = epochs.events[:, -1] - 2\n",
    "\n",
    "    return epochs_data, labels"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#----------------------- physionet dataset -------------------------------------\n",
    "# [6, 10, 14] hands vs feet\n",
    "#[4, 8, 12] left vs right hand\n",
    "# X_hf, y_hf = get_physionet_data(subject=1, runs=[6, 10, 14])\n",
    "# X_lr, y_lr = get_physionet_data(subject=1, runs=[4, 8, 12])\n",
    "#\n",
    "# epochs = mne.concatenate_epochs([X_hf, X_lr])\n",
    "# labels = np.concatenate([y_hf, y_lr+2])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X = torch.tensor(epochs.get_data()).to(dtype=torch.float32, device=device)\n",
    "y = torch.tensor(labels).to(dtype=torch.long, device=device)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from Models.SubModules import ViewConv, DepthWiseConv2d, SeparableConv2d, Unsqueeze, PositionalEncoding, ToTransformer, \\\n",
    "    MaxNormLayer\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class EEGNET(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            n_channels,\n",
    "            n_times,\n",
    "            n_classes,\n",
    "            kernel_length=64,\n",
    "            F1=8,\n",
    "            D=2,\n",
    "            F2=16,\n",
    "            signal_size=32,\n",
    "            pool1_stride=4,\n",
    "            pool2_stride=8,\n",
    "            dropout_rate=0.5,\n",
    "            norm_rate=0.25,\n",
    "            transformer_ffd=516,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        print('model instantianting...')\n",
    "        self.net = nn.Sequential(\n",
    "            ViewConv(),\n",
    "            nn.Conv2d(in_channels=n_channels, out_channels=F1, kernel_size=(1, kernel_length), bias=False, padding='same'),\n",
    "            nn.BatchNorm2d(num_features=F1, momentum=0.01, eps=0.001, track_running_stats=False),\n",
    "            DepthWiseConv2d(in_channels=F1, kernel_size=(n_channels, 1), kernels_per_layer=D, bias=False),\n",
    "            nn.BatchNorm2d(num_features=F1*D, momentum=0.01, eps=0.001, track_running_stats=False),\n",
    "            nn.ELU(),\n",
    "            nn.AvgPool2d(kernel_size=(1, pool1_stride), stride=pool1_stride),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            SeparableConv2d(in_channels=F1*D, kernel_size=(1, 16), out_channels=F2, bias=False),\n",
    "            nn.BatchNorm2d(num_features=F2, momentum=0.01, eps=0.001, track_running_stats=False),\n",
    "            nn.ELU(),\n",
    "            nn.AvgPool2d(kernel_size=(1, pool2_stride), stride=pool2_stride),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=F2 * ((((n_times - pool1_stride) // pool1_stride + 1) - pool2_stride) // pool2_stride + 1), out_features=signal_size, bias=False),\n",
    "            nn.ELU(),\n",
    "            Unsqueeze(),\n",
    "            PositionalEncoding(d_model=signal_size, dropout=0.1),\n",
    "            ToTransformer(),\n",
    "            nn.TransformerEncoder(\n",
    "                nn.TransformerEncoderLayer(d_model=signal_size, dim_feedforward=transformer_ffd, nhead=4, batch_first=True),\n",
    "                num_layers=2,\n",
    "            ),\n",
    "            # ViewConv(),\n",
    "            # nn.Conv2d(in_channels=signal_size, out_channels=1, kernel_size=(1, signal_size), bias=False, padding='same'),\n",
    "            # nn.Flatten(),\n",
    "\n",
    "            nn.AvgPool1d(kernel_size=4, stride=signal_size),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Flatten(),\n",
    "            nn.BatchNorm1d(num_features=signal_size, momentum=0.01, eps=0.001, track_running_stats=False),\n",
    "            nn.ELU(),\n",
    "            MaxNormLayer(in_features=signal_size, out_features=n_classes, max_norm=norm_rate),\n",
    "            nn.Softmax(dim=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, targets):\n",
    "        out_values = {}\n",
    "        out = x\n",
    "\n",
    "        for layer in self.net.children():\n",
    "            out = layer(out)\n",
    "            out_values[layer.__class__.__name__] = out.clone()\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            loss = F.cross_entropy(out, targets)\n",
    "\n",
    "        return out, loss, out_values"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# from Models.ImprovedTransformer import EEGNET\n",
    "\n",
    "#MOABB\n",
    "# model = EEGNET(n_channels=len(epochs.picks), n_times=1251, n_classes=len(data_handler.selected_events))\n",
    "\n",
    "#UFJF\n",
    "model = EEGNET(n_channels=len(epochs.picks), n_times=X.shape[-1], n_classes=4)\n",
    "\n",
    "model = model.to(device=device)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "seed = 1337\n",
    "splits = 5\n",
    "lr=1e-3\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, random_state=seed, shuffle=True)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from modules.TrainTester import TrainerTester\n",
    "\n",
    "ud = []\n",
    "\n",
    "#main-trianing-loop\n",
    "for train_index, test_index in skf.split(X[:-100], y[:-100]):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    TrainerTester.train_loop(model, optimizer, X_train, y_train, lr, ud)\n",
    "    out_values = TrainerTester.test_loop(model, X_test, y_test)\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "out_values = TrainerTester.test_loop(model, X[-100:], y[-100:])\n",
    "accuracy = TrainerTester.test_and_show(model, X[-100:], y[-100:]).tolist()\n",
    "\n",
    "plt.plot(accuracy)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "accuracy = []\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    out_values = TrainerTester.test_loop(model, X_test, y_test)\n",
    "    accuracy.append(TrainerTester.test_and_show(model, X_test[:-10], y_test[:-10]).tolist())\n",
    "    break\n",
    "\n",
    "plt.imshow(accuracy, cmap=\"Blues\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#params evaluation\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, np.prod(param.size()))\n",
    "\n",
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "print('total: ', params)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(40, 10))\n",
    "legends = []\n",
    "i = 0\n",
    "for name, p in model.named_parameters():\n",
    "    plt.plot([ud[j][i] for j in range(len(ud))])\n",
    "    legends.append(name)\n",
    "    i += 1\n",
    "plt.plot([0, len(ud)], [-3, -3], 'k') # these ratios should be ~1e-3, indicate on plot\n",
    "plt.legend(legends);"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# visualize histograms\n",
    "plt.figure(figsize=(40, 30)) # width and height of the plot\n",
    "legends = []\n",
    "for name, values in out_values.items(): # note: exclude the output value\n",
    "    if name != \"Softmax\":\n",
    "        t = values\n",
    "        print(f'{name}: mean {t.mean()}, std {t.std()}')\n",
    "        hy, hx = torch.histogram(t, density=True)\n",
    "        plt.plot(hx[:-1].detach(), hy.detach())\n",
    "        legends.append(f'layer ({name}')\n",
    "plt.legend(legends)\n",
    "plt.title('gradient distribution')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import re\n",
    "# visualize histograms\n",
    "plt.figure(figsize=(40, 20)) # width and height of the plot\n",
    "legends = []\n",
    "for name, params in model.named_parameters():\n",
    "    if not re.search('bias', name):\n",
    "        t = params.grad\n",
    "        print(f'layer {name}: weight {tuple(params.shape)} | mean {t.mean()} | std {t.std()} | grad:data ratio { t.std() / params.std()}')\n",
    "        hy, hx = torch.histogram(t, density=True)\n",
    "        plt.plot(hx[:-1].detach(), hy.detach())\n",
    "        legends.append(f'{name} {tuple(params.shape)}')\n",
    "plt.legend(legends)\n",
    "plt.title('weights gradient distribution');"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('model_states/model_states.txt'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), 'model_states/model_states.txt')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
