{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import sys\n",
    "import random\n",
    "\n",
    "import mne\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import math\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "import importlib\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
    "%matplotlib inline"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from modules.BciDataHandler import BciDataHandler\n",
    "\n",
    "data_handler = BciDataHandler()\n",
    "data_handler.instantiate_dataset()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ------------------------------ bci competition dataset ------------------------------\n",
    "all_subject_epochs = mne.concatenate_epochs(list(data_handler.subjects_epochs.values()))\n",
    "all_labels = all_subject_epochs.events[:, -1] - 1\n",
    "\n",
    "epochs = data_handler.subjects_epochs[1]\n",
    "labels = np.array(data_handler.subjects_labels[1]) - 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# -------------------------------- ufjf dataset --------------------------------------\n",
    "# from modules.EdfHandler import EdfHandler\n",
    "#\n",
    "# epochs, labels = EdfHandler.getAllData([\"C:\\\\Users\\\\davi2\\Desktop\\\\bci\\\\datasets_ufjf\\\\bci\\\\001.edf\"])\n",
    "# epochs = epochs[0]\n",
    "# labels = np.array(labels[0])\n",
    "# labels[labels == 6] = 0"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import mne\n",
    "from mne import Epochs, pick_types, events_from_annotations\n",
    "from mne.channels import make_standard_montage\n",
    "from mne.io import concatenate_raws, read_raw_edf\n",
    "from mne.datasets import eegbci\n",
    "\n",
    "\n",
    "# #############################################################################\n",
    "# # Set parameters and read data\n",
    "\n",
    "# avoid classification of evoked responses by using epochs that start 1s after\n",
    "# cue onset.\n",
    "tmin, tmax = -1., 4.\n",
    "event_id = dict(handsOrLeft=2, feetOrRight=3)\n",
    "\n",
    "def get_physionet_data(subject, runs):\n",
    "\n",
    "    raw_fnames = eegbci.load_data(subject, runs)\n",
    "    raw = concatenate_raws([read_raw_edf(f, preload=True) for f in raw_fnames])\n",
    "    eegbci.standardize(raw)  # set channel names\n",
    "    montage = make_standard_montage('standard_1005')\n",
    "    raw.set_montage(montage)\n",
    "\n",
    "    # Apply band-pass filter\n",
    "    raw.filter(7., 30., fir_design='firwin', skip_by_annotation='edge')\n",
    "\n",
    "    events, _ = events_from_annotations(raw)\n",
    "\n",
    "    picks = pick_types(raw.info, meg=False, eeg=True, stim=False, eog=False,\n",
    "                       exclude='bads')\n",
    "\n",
    "    # Read epochs (train will be done only between 1 and 2s)\n",
    "    # Testing will be done with a running classifier\n",
    "    epochs = Epochs(raw, events, event_id, tmin, tmax, proj=True, picks=picks,\n",
    "                    baseline=None, preload=True)\n",
    "\n",
    "    epochs_data = epochs.copy().crop(tmin=1., tmax=2.)\n",
    "\n",
    "    labels = epochs.events[:, -1] - 2\n",
    "\n",
    "    return epochs_data, labels"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#----------------------- physionet dataset -------------------------------------\n",
    "# [6, 10, 14] hands vs feet\n",
    "#[4, 8, 12] left vs right hand\n",
    "# X_hf, y_hf = get_physionet_data(subject=1, runs=[6, 10, 14])\n",
    "# X_lr, y_lr = get_physionet_data(subject=1, runs=[4, 8, 12])\n",
    "#\n",
    "# epochs = mne.concatenate_epochs([X_hf, X_lr])\n",
    "# labels = np.concatenate([y_hf, y_lr+2])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class ViewConv2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self,x):\n",
    "        return x.view((x.shape[0], x.shape[1], 1, x.shape[2]))\n",
    "\n",
    "class Unsqueeze2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.view((x.shape[0], x.shape[1], 1))\n",
    "\n",
    "class EmbeddingLayer(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            n_times,\n",
    "            patches_num,\n",
    "            embedding_dim,\n",
    "            dropout_rate,\n",
    "            depth=1\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.patches_num = patches_num\n",
    "        self.embedding = nn.Linear(in_features=math.ceil(n_times*depth/self.patches_num), out_features=embedding_dim)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.positional_encode_table = nn.Embedding(num_embeddings=self.patches_num, embedding_dim=embedding_dim)\n",
    "\n",
    "    #output shape -> [Batches, embeding dim, pathces,]\n",
    "    def forward(self, x):\n",
    "        patches = list(x.chunk(self.patches_num, dim=-1))\n",
    "        patches[-1] = F.pad(patches[-1], (0, patches[0].shape[-1] - patches[-1].shape[-1]))\n",
    "        patches = torch.stack(patches, dim=-2)\n",
    "\n",
    "        #creating new dimesion for embedding (its not -1 to not bug the matrix mul)\n",
    "        patches = patches.unsqueeze(-2)\n",
    "        embedding_result = self.embedding(patches)\n",
    "\n",
    "        #creating removing the unnecessary dimension to add the positional encode\n",
    "        embedding_result = embedding_result.squeeze(-2)\n",
    "        positional_result = embedding_result + self.positional_encode_table((torch.arange(self.patches_num, device=device)))\n",
    "        out = self.dropout(positional_result)\n",
    "\n",
    "        return out.view(out.shape[0], out.shape[2], out.shape[1])\n",
    "        # return out.view(out.shape[0], out.shape[1], out.shape[3], out.shape[2])\n",
    "\n",
    "class VisionTransformer(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            patches,\n",
    "            transformer_ffd,\n",
    "            nhead = 8,\n",
    "            num_layers=2\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.transformer = nn.Sequential(\n",
    "            nn.TransformerEncoder(\n",
    "                nn.TransformerEncoderLayer(d_model=patches, dim_feedforward=transformer_ffd, nhead=nhead, batch_first=True),\n",
    "                num_layers=num_layers,\n",
    "            ),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.transformer(x)\n",
    "\n",
    "\n",
    "class ConvolutionSimplifier(nn.Module):\n",
    "    def __init__(self, embedding_dim, dropout_rate):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool1d(output_size=1),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Flatten(),\n",
    "            nn.LayerNorm(normalized_shape=embedding_dim),\n",
    "            nn.ELU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class FeatureExtraction(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            n_channels,\n",
    "            kernel_length,\n",
    "            F1,\n",
    "            D,\n",
    "            F2,\n",
    "            pool1_stride,\n",
    "            pool2_stride,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            ViewConv(),\n",
    "            nn.Conv2d(in_channels=n_channels, out_channels=F1, kernel_size=(1, kernel_length), bias=False, padding='same'),\n",
    "            nn.BatchNorm2d(num_features=F1, momentum=0.01, eps=0.001, track_running_stats=False),\n",
    "            DepthWiseConv2d(in_channels=F1, kernel_size=(n_channels, 1), kernels_per_layer=D, bias=False),\n",
    "            nn.BatchNorm2d(num_features=F1*D, momentum=0.01, eps=0.001, track_running_stats=False),\n",
    "            nn.ELU(),\n",
    "            nn.AvgPool2d(kernel_size=(1, pool1_stride), stride=pool1_stride),\n",
    "            SeparableConv2d(in_channels=F1*D, kernel_size=(1, 16), out_channels=F2, bias=False),\n",
    "            nn.BatchNorm2d(num_features=F2, momentum=0.01, eps=0.001, track_running_stats=False),\n",
    "            nn.ELU(),\n",
    "            nn.AvgPool2d(kernel_size=(1, pool2_stride), stride=pool2_stride),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from Models.SubModules import ViewConv, DepthWiseConv2d, SeparableConv2d, Unsqueeze, PositionalEncoding, ToTransformer, \\\n",
    "    MaxNormLayer\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class EEGNET(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            n_times,\n",
    "            n_classes,\n",
    "            n_channels,\n",
    "            patches=32,\n",
    "            embedding_dim=16,\n",
    "            dropout_rate=0.1,\n",
    "            transformer_ffd=128,\n",
    "            max_norm=0.25,\n",
    "            F1=8,\n",
    "            F2=16,\n",
    "            D=2,\n",
    "            pool1_stride=4,\n",
    "            pool2_stride=8,\n",
    "            kernel_length=64,\n",
    "            channel_depht=1\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.feature_extraction_output = F2 * ((((n_times - pool1_stride) // pool1_stride + 1) - pool2_stride) // pool2_stride + 1)\n",
    "\n",
    "        self.feature_extraction = FeatureExtraction(n_channels=n_channels, kernel_length=kernel_length, F1=F1, D=D, F2=F2, pool1_stride=pool1_stride, pool2_stride=pool2_stride)\n",
    "\n",
    "        self.embedding = EmbeddingLayer(n_times=self.feature_extraction_output, patches_num=patches, embedding_dim=embedding_dim, dropout_rate=dropout_rate)\n",
    "\n",
    "        self.transformer = VisionTransformer(patches=patches, transformer_ffd=transformer_ffd)\n",
    "\n",
    "        self.conv_simplifier = ConvolutionSimplifier(embedding_dim=embedding_dim, dropout_rate=dropout_rate)\n",
    "\n",
    "        self.head = nn.Sequential(\n",
    "           MaxNormLayer(in_features=embedding_dim, out_features=n_classes, max_norm=max_norm),\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x, targets):\n",
    "        out_values = {}\n",
    "        out = self.feature_extraction(x)\n",
    "        out = self.embedding(out)\n",
    "        out = self.transformer(out)\n",
    "        out = self.conv_simplifier(out)\n",
    "        logits = self.head(out)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss, out_values"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X = torch.tensor(epochs.get_data()).to(dtype=torch.float32, device=device)\n",
    "y = torch.tensor(labels).to(dtype=torch.long, device=device)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#data augmentation\n",
    "from braindecode.augmentation import FrequencyShift\n",
    "from braindecode.augmentation import GaussianNoise\n",
    "\n",
    "sfreq = epochs.info['sfreq']\n",
    "\n",
    "freq_shift = FrequencyShift(\n",
    "    probability=0.8,  # defines the probability of actually modifying the input\n",
    "    sfreq=sfreq,\n",
    "    max_delta_freq=2.  # the frequency shifts are sampled now between -2 and 2 Hz\n",
    ")\n",
    "\n",
    "gauss_noise = GaussianNoise(\n",
    "    probability=0.8,\n",
    "    std=0.01\n",
    ")\n",
    "\n",
    "transforms = {\n",
    "    'freq': freq_shift,\n",
    "    'gauss': gauss_noise\n",
    "}\n",
    "\n",
    "X_tr, _ = freq_shift.operation(X, None, 10., sfreq)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_psd(data, axis, label, color):\n",
    "    psds, freqs = mne.time_frequency.psd_array_multitaper(data, sfreq=sfreq,\n",
    "                                                          fmin=0.1, fmax=100)\n",
    "    psds = 10. * np.log10(psds)\n",
    "    psds_mean = psds.mean(0).mean(0)\n",
    "    axis.plot(freqs, psds_mean, color=color, label=label)\n",
    "\n",
    "\n",
    "_, ax = plt.subplots()\n",
    "plot_psd(X, ax, 'original', 'k')\n",
    "plot_psd(X_tr.numpy(), ax, 'shifted', 'r')\n",
    "\n",
    "ax.set(title='Multitaper PSD (gradiometers)', xlabel='Frequency (Hz)',\n",
    "       ylabel='Power Spectral Density (dB)')\n",
    "ax.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "\n",
    "class TrainerTester:\n",
    "\n",
    "    @staticmethod\n",
    "    def train_loop(model, optimizer, X_train, y_train, x_test, y_test, lr, ud, batch_size=32, iterations=1000):\n",
    "        lossi = []\n",
    "        accuracyi = []\n",
    "        lossv = []\n",
    "        accuracyv = []\n",
    "        for k in range(iterations):\n",
    "            batch_indexes = torch.randint(0, X_train.shape[0], (batch_size,))\n",
    "            batch_test_indexes = torch.randint(0, X_test.shape[0], (batch_size,))\n",
    "\n",
    "            X_batch, y_batch = X_train[batch_indexes], y_train[batch_indexes]  # train batch X,Y\n",
    "\n",
    "            #data augmentation\n",
    "            # X_batch, _ = transforms['freq'].operation(X_batch, None, 10., sfreq)\n",
    "            # X_batch, _ = transforms['gauss'].operation(X_batch, None, std=1e-5)\n",
    "\n",
    "            X_test_batch, y_test_batch = X_test[batch_test_indexes], y_test[batch_test_indexes]  # test batch X,Y\n",
    "\n",
    "            pred, loss, out_values = model(X_batch,  y_batch)\n",
    "\n",
    "            # Backpropagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                #tracking training metrics\n",
    "                lossi.append(loss.item())\n",
    "                accuracyi.append((pred.argmax(1) == y_batch).type(torch.float32).sum().item() / y_batch.shape[0])\n",
    "\n",
    "                #tracking test metrics\n",
    "                test_loss, test_accuracy = TrainerTester.test_loss(model, X_test_batch, y_test_batch)\n",
    "                lossv.append(test_loss)\n",
    "                accuracyv.append(test_accuracy)\n",
    "\n",
    "                if (k+1) % 100 == 0:\n",
    "                    print(f\"loss: {loss} iteration: {k+1}/{iterations}\")\n",
    "                    plt.title('loss')\n",
    "                    plt.plot(torch.tensor(lossv).view(-1, 10).mean(dim=1).tolist(), label=\"test loss\")\n",
    "                    plt.plot(torch.tensor(lossi).view(-1, 10).mean(dim=1).tolist(), label=\"train loss\")\n",
    "                    plt.show()\n",
    "\n",
    "                    plt.title('accuracy')\n",
    "                    plt.plot(torch.tensor(accuracyv).view(-1, 10).mean(dim=1).tolist(), label=\"test accuracy\")\n",
    "                    plt.plot(torch.tensor(accuracyi).view(-1, 10).mean(dim=1).tolist(), label=\"train accuracy\")\n",
    "                    plt.show()\n",
    "\n",
    "                ud.append([((lr * p.grad).std() / p.data.std()).item() for p in model.parameters()])\n",
    "\n",
    "        return lossi\n",
    "\n",
    "    @staticmethod\n",
    "    def test_loss(model, X_test,  y_test):\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            pred, loss, out_values = model(X_test, y_test)\n",
    "            accuracy = (pred.argmax(1) == y_test).type(torch.float32).sum().item() / y_test.shape[0]\n",
    "        model.train()\n",
    "        return loss, accuracy\n",
    "\n",
    "    @staticmethod\n",
    "    def test_loop(model, X_test,  y_test):\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            pred, loss, out_values = model(X_test, y_test)\n",
    "            accuracy = (pred.argmax(1) == y_test).type(torch.float32).sum().item() / y_test.shape[0]\n",
    "            kappa = cohen_kappa_score(pred.argmax(1), y_test)\n",
    "\n",
    "        print(f\"Test loss: {loss:>8f} \\n Accuracy: {accuracy:>8f} \\n kappa: {kappa} \\n\")\n",
    "        model.train()\n",
    "        return out_values\n",
    "\n",
    "    @staticmethod\n",
    "    def test_and_show(model, X_test,  y_test):\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            pred, loss, out_values = model(X_test,  y_test)\n",
    "            accuracy = pred.argmax(1) == y_test\n",
    "            model.train()\n",
    "            return accuracy\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = EEGNET(n_times=X.shape[-1], n_channels=len(epochs.picks), n_classes=4)\n",
    "model = model.to(device=device)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "seed = 1330\n",
    "splits = 5\n",
    "lr=3e-3\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, random_state=seed, shuffle=True)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=0.3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_24216\\2452553826.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      6\u001B[0m     \u001B[0my_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_test\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mtrain_index\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mtest_index\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 8\u001B[1;33m     \u001B[0mTrainerTester\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtrain_loop\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0moptimizer\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mX_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mX_test\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_test\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlr\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mud\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbatch_size\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m32\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0miterations\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m2000\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      9\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     10\u001B[0m     \u001B[0mout_values\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mTrainerTester\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtest_loop\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mX_test\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_test\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_24216\\367227786.py\u001B[0m in \u001B[0;36mtrain_loop\u001B[1;34m(model, optimizer, X_train, y_train, x_test, y_test, lr, ud, batch_size, iterations)\u001B[0m\n\u001B[0;32m     54\u001B[0m                     \u001B[0mplt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshow\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     55\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 56\u001B[1;33m                 \u001B[0mud\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlr\u001B[0m \u001B[1;33m*\u001B[0m \u001B[0mp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mgrad\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstd\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m/\u001B[0m \u001B[0mp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstd\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mitem\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mp\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mparameters\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     57\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     58\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mlossi\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_24216\\367227786.py\u001B[0m in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m     54\u001B[0m                     \u001B[0mplt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshow\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     55\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 56\u001B[1;33m                 \u001B[0mud\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mlr\u001B[0m \u001B[1;33m*\u001B[0m \u001B[0mp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mgrad\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstd\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m/\u001B[0m \u001B[0mp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstd\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mitem\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mp\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mparameters\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     57\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     58\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mlossi\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "ud = []\n",
    "\n",
    "#main-trianing-loop\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train,  X_test = X[train_index], X[test_index],\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    TrainerTester.train_loop(model, optimizer, X_train, y_train, X_test, y_test, lr, ud, batch_size=32, iterations=2000)\n",
    "\n",
    "    out_values = TrainerTester.test_loop(model, X_test, y_test)\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#params evaluation\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, np.prod(param.size()))\n",
    "\n",
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "print('total: ', params)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "legends = []\n",
    "i = 0\n",
    "for name, p in model.named_parameters():\n",
    "    plt.plot([ud[j][i] for j in range(len(ud))])\n",
    "    legends.append(name)\n",
    "    i += 1\n",
    "plt.plot([0, len(ud)], [-3, -3], 'k') # these ratios should be ~1e-3, indicate on plot\n",
    "plt.legend(legends);"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# visualize histograms\n",
    "plt.figure(figsize=(40, 30)) # width and height of the plot\n",
    "legends = []\n",
    "for name, values in out_values.items(): # note: exclude the output value\n",
    "    if name != \"Softmax\":\n",
    "        t = values\n",
    "        print(f'{name}: mean {t.mean()}, std {t.std()}')\n",
    "        hy, hx = torch.histogram(t, density=True)\n",
    "        plt.plot(hx[:-1].detach(), hy.detach())\n",
    "        legends.append(f'layer ({name}')\n",
    "plt.legend(legends)\n",
    "plt.title('gradient distribution')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import re\n",
    "# visualize histograms\n",
    "plt.figure(figsize=(40, 20)) # width and height of the plot\n",
    "legends = []\n",
    "for name, params in model.named_parameters():\n",
    "    if not re.search('bias', name):\n",
    "        t = params.grad\n",
    "        print(f'layer {name}: weight {tuple(params.shape)} | mean {t.mean()} | std {t.std()} | grad:data ratio { t.std() / params.std()}')\n",
    "        hy, hx = torch.histogram(t, density=True)\n",
    "        plt.plot(hx[:-1].detach(), hy.detach())\n",
    "        legends.append(f'{name} {tuple(params.shape)}')\n",
    "plt.legend(legends)\n",
    "plt.title('weights gradient distribution');"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import re\n",
    "# visualize histograms\n",
    "plt.figure(figsize=(20, 10)) # width and height of the plot\n",
    "legends = []\n",
    "for name, params in model.named_parameters():\n",
    "    if not re.search('bias', name) and not re.search('norm', name):\n",
    "        t = params\n",
    "        print(f'layer {name}: weight {tuple(params.shape)} | mean {t.mean()} | std {t.std()} | weight:data ratio { t.std() / params.std()}')\n",
    "        hy, hx = torch.histogram(t, density=True)\n",
    "        plt.plot(hx[:-1].detach(), hy.detach())\n",
    "        legends.append(f'{name} {tuple(params.shape)}')\n",
    "plt.legend(legends)\n",
    "plt.title('weights distribution');"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('model_states/test_model_states.txt'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), 'model_states/test_model_states.txt')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
