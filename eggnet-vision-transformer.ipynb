{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import sys\n",
    "import random\n",
    "\n",
    "import mne\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import math\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "import importlib\n",
    "from einops import rearrange, reduce, repeat\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
    "%matplotlib inline"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def unfold_output_size(n_times, patches, step):\n",
    "    return (n_times - patches) / step + 1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from modules.BciDataHandler import BciDataHandler\n",
    "\n",
    "data_handler = BciDataHandler()\n",
    "data_handler.instantiate_dataset()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ------------------------------ bci competition dataset ------------------------------\n",
    "all_subject_epochs = mne.concatenate_epochs(list(data_handler.subjects_epochs.values()))\n",
    "all_labels = all_subject_epochs.events[:, -1] - 1\n",
    "\n",
    "epochs = data_handler.subjects_epochs[1]\n",
    "labels = np.array(data_handler.subjects_labels[1]) - 1\n",
    "\n",
    "# epochs = all_subject_epochs\n",
    "# labels = all_labels\n",
    "# labels"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# -------------------------------- ufjf dataset --------------------------------------\n",
    "# from modules.EdfHandler import EdfHandler\n",
    "#\n",
    "# epochs, labels = EdfHandler.getAllData([\"C:\\\\Users\\\\davi2\\Desktop\\\\bci\\\\datasets_ufjf\\\\bci\\\\001.edf\"])\n",
    "# epochs = epochs[0]\n",
    "# labels = np.array(labels[0])\n",
    "# labels[labels == 6] = 0"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#----------------------- physionet dataset -------------------------------------\n",
    "# import mne\n",
    "# from mne import Epochs, pick_types, events_from_annotations\n",
    "# from mne.channels import make_standard_montage\n",
    "# from mne.io import concatenate_raws, read_raw_edf\n",
    "# from mne.datasets import eegbci\n",
    "#\n",
    "#\n",
    "# #############################################################################\n",
    "# # Set parameters and read data\n",
    "#\n",
    "# # avoid classification of evoked responses by using epochs that start 1s after\n",
    "# # cue onset.\n",
    "# tmin, tmax = -1., 4.\n",
    "# event_id = dict(handsOrLeft=2, feetOrRight=3)\n",
    "#\n",
    "# def get_physionet_data(subject, runs):\n",
    "#\n",
    "#     raw_fnames = eegbci.load_data(subject, runs)\n",
    "#     raw = concatenate_raws([read_raw_edf(f, preload=True) for f in raw_fnames])\n",
    "#     eegbci.standardize(raw)  # set channel names\n",
    "#     montage = make_standard_montage('standard_1005')\n",
    "#     raw.set_montage(montage)\n",
    "#\n",
    "#     # Apply band-pass filter\n",
    "#     raw.filter(7., 30., fir_design='firwin', skip_by_annotation='edge')\n",
    "#\n",
    "#     events, _ = events_from_annotations(raw)\n",
    "#\n",
    "#     picks = pick_types(raw.info, meg=False, eeg=True, stim=False, eog=False,\n",
    "#                        exclude='bads')\n",
    "#\n",
    "#     # Read epochs (train will be done only between 1 and 2s)\n",
    "#     # Testing will be done with a running classifier\n",
    "#     epochs = Epochs(raw, events, event_id, tmin, tmax, proj=True, picks=picks,\n",
    "#                     baseline=None, preload=True)\n",
    "#\n",
    "#     epochs_data = epochs.copy().crop(tmin=1., tmax=2.)\n",
    "#\n",
    "#     labels = epochs.events[:, -1] - 2\n",
    "#\n",
    "#     return epochs_data, labels\n",
    "#\n",
    "#\n",
    "# # [6, 10, 14] hands vs feet\n",
    "# # [4, 8, 12] left vs right hand\n",
    "# X_hf, y_hf = get_physionet_data(subject=1, runs=[6, 10, 14])\n",
    "# X_lr, y_lr = get_physionet_data(subject=1, runs=[4, 8, 12])\n",
    "#\n",
    "# epochs = mne.concatenate_epochs([X_hf, X_lr])\n",
    "# labels = np.concatenate([y_hf, y_lr+2])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# def plot_psd(data, axis, label, color):\n",
    "#     psds, freqs = mne.time_frequency.psd_array_multitaper(data, sfreq=sfreq,\n",
    "#                                                           fmin=0.1, fmax=100)\n",
    "#     psds = 10. * np.log10(psds)\n",
    "#     psds_mean = psds.mean(0).mean(0)\n",
    "#     axis.plot(freqs, psds_mean, color=color, label=label)\n",
    "#\n",
    "#\n",
    "# _, ax = plt.subplots()\n",
    "# plot_psd(X, ax, 'original', 'k')\n",
    "# plot_psd(X_tr.numpy(), ax, 'shifted', 'r')\n",
    "#\n",
    "# ax.set(title='Multitaper PSD (gradiometers)', xlabel='Frequency (Hz)',\n",
    "#        ylabel='Power Spectral Density (dB)')\n",
    "# ax.legend()\n",
    "# plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def exists(val):\n",
    "    return val is not None\n",
    "\n",
    "class MyViTransformerWrapper(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            *,\n",
    "            image_size,\n",
    "            patch_size,\n",
    "            attn_layers,\n",
    "            channels,\n",
    "            num_classes = None,\n",
    "            dropout = 0.,\n",
    "            post_emb_norm = False,\n",
    "            emb_dropout = 0.\n",
    "    ):\n",
    "        super().__init__()\n",
    "        assert isinstance(attn_layers, Encoder), 'attention layers must be an Encoder'\n",
    "        assert image_size % patch_size == 0, 'image dimensions must be divisible by the patch size'\n",
    "        dim = attn_layers.dim\n",
    "        num_patches = (image_size // patch_size)\n",
    "        patch_dim = channels * patch_size\n",
    "\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "        self.pos_embedding = nn.Parameter(torch.randn(num_patches, dim))\n",
    "\n",
    "        self.patch_to_embedding = nn.Sequential(\n",
    "            nn.LayerNorm(patch_dim),\n",
    "            nn.Linear(patch_dim, dim),\n",
    "            nn.LayerNorm(dim)\n",
    "        )\n",
    "\n",
    "        self.post_emb_norm = nn.LayerNorm(dim) if post_emb_norm else nn.Identity()\n",
    "        self.dropout = nn.Dropout(emb_dropout)\n",
    "\n",
    "        self.attn_layers = attn_layers\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "        self.mlp_head = nn.Linear(dim, num_classes) if exists(num_classes) else nn.Identity()\n",
    "\n",
    "    def forward(\n",
    "            self,\n",
    "            img,\n",
    "            return_embeddings = False\n",
    "    ):\n",
    "        p = self.patch_size\n",
    "        img = img.unsqueeze(-2)\n",
    "        x = rearrange(img, 'b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1 = 1, p2 = p)\n",
    "        x = self.patch_to_embedding(x)\n",
    "        n = x.shape[1]\n",
    "\n",
    "        x = x + self.pos_embedding[:, :n]\n",
    "\n",
    "        x = self.post_emb_norm(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.attn_layers(x)\n",
    "        x = self.norm(x)\n",
    "\n",
    "        if not exists(self.mlp_head) or return_embeddings:\n",
    "            return x\n",
    "\n",
    "        x = x.mean(dim = -2)\n",
    "        return self.mlp_head(x)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from x_transformers import TransformerWrapper, Encoder, ViTransformerWrapper\n",
    "\n",
    "\n",
    "class DepthWiseConv2d(nn.Module):\n",
    "    def __init__(self, in_channels, kernel_size, kernels_per_layer, bias=False):\n",
    "        super().__init__()\n",
    "        self.depthwise = nn.Conv2d(in_channels=in_channels, out_channels=in_channels * kernels_per_layer,\n",
    "                                   kernel_size=kernel_size, groups=in_channels, bias=bias, padding='same')\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.depthwise(x)\n",
    "\n",
    "\n",
    "class PointWiseConv2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernels_per_layer=1, bias=False):\n",
    "        super().__init__()\n",
    "        self.pointwise = nn.Conv2d(in_channels=in_channels * kernels_per_layer, out_channels=out_channels,\n",
    "                                   kernel_size=(1, 1), bias=bias, padding=\"valid\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.pointwise(x)\n",
    "\n",
    "\n",
    "class MaxNormLayer(nn.Linear):\n",
    "    def __init__(self, in_features, out_features, max_norm=1.0):\n",
    "        super(MaxNormLayer, self).__init__(in_features=in_features, out_features=out_features)\n",
    "        self.max_norm = max_norm\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.max_norm is not None:\n",
    "            with torch.no_grad():\n",
    "                self.weight.data = torch.renorm(\n",
    "                    self.weight.data, p=2, dim=0, maxnorm=self.max_norm\n",
    "                )\n",
    "        return super(MaxNormLayer, self).forward(x)\n",
    "\n",
    "\n",
    "class SeparableConv2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, kernels_per_layer=1, bias=False):\n",
    "        super().__init__()\n",
    "        self.depthwise = DepthWiseConv2d(in_channels=in_channels, kernels_per_layer=kernels_per_layer,\n",
    "                                         kernel_size=kernel_size, bias=bias)\n",
    "        self.pointwise = PointWiseConv2d(in_channels=in_channels, out_channels=out_channels,\n",
    "                                         kernels_per_layer=kernels_per_layer, bias=bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.depthwise(x)\n",
    "        x = self.pointwise(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ViewConv(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.view((x.shape[0], x.shape[1], 1, x.shape[2]))\n",
    "\n",
    "\n",
    "\n",
    "class FeatureExtraction(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            n_channels,\n",
    "            kernel_length,\n",
    "            F1,\n",
    "            D,\n",
    "            F2,\n",
    "            pool1_stride,\n",
    "            pool2_stride,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            ViewConv(),\n",
    "            nn.Conv2d(in_channels=n_channels, out_channels=F1, kernel_size=(1, kernel_length), bias=False,\n",
    "                      padding='same'),\n",
    "            nn.BatchNorm2d(num_features=F1, momentum=0.01, eps=0.001, track_running_stats=False),\n",
    "            DepthWiseConv2d(in_channels=F1, kernel_size=(n_channels, 1), kernels_per_layer=D, bias=False),\n",
    "            nn.BatchNorm2d(num_features=F1 * D, momentum=0.01, eps=0.001, track_running_stats=False),\n",
    "            nn.ELU(),\n",
    "            nn.AvgPool2d(kernel_size=(1, pool1_stride), stride=pool1_stride),\n",
    "            SeparableConv2d(in_channels=F1 * D, kernel_size=(1, 16), out_channels=F2, bias=False),\n",
    "            nn.BatchNorm2d(num_features=F2, momentum=0.01, eps=0.001, track_running_stats=False),\n",
    "            nn.ELU(),\n",
    "            nn.AvgPool2d(kernel_size=(1, pool2_stride), stride=pool2_stride),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from einops.layers.torch import Rearrange, Reduce\n",
    "\n",
    "class PatchEmbedding(nn.Module):\n",
    "    def __init__(self, in_channels, patch_size, emb_size, signal_size):\n",
    "        super().__init__()\n",
    "        self.patch_size = patch_size\n",
    "        self.projection = nn.Sequential(\n",
    "            # using a conv layer instead of a linear one -> performance gains\n",
    "            nn.Conv2d(in_channels, emb_size, kernel_size=(1, patch_size), stride=patch_size),\n",
    "            Rearrange('b e (h) (w) -> b (h w) e'),\n",
    "        )\n",
    "        self.cls_token = nn.Parameter(torch.randn(1,1, emb_size))\n",
    "        self.positions = nn.Parameter(torch.randn((signal_size // patch_size) + 1, emb_size))\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        b, _, _, _ = x.shape\n",
    "        x = self.projection(x)\n",
    "        cls_tokens = repeat(self.cls_token, '() n e -> b n e', b=b)\n",
    "        # prepend the cls token to the input\n",
    "        x = torch.cat([cls_tokens, x], dim=1)\n",
    "        # add position embedding\n",
    "        x += self.positions\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class EEGNET(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            n_times,\n",
    "            n_classes,\n",
    "            n_channels,\n",
    "            patches_size=9,\n",
    "            embedding_dim=32,\n",
    "            transformer_ffd=128,\n",
    "            transformer_layers=2,\n",
    "            transformer_heads=2,\n",
    "            dropout_rate=0.1,\n",
    "            max_norm=0.25,\n",
    "            F1=8,\n",
    "            F2=16,\n",
    "            D=2,\n",
    "            pool1_stride=4,\n",
    "            pool2_stride=8,\n",
    "            kernel_length=4,\n",
    "            n_hidden=32,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.feature_extraction_output = F2 * ((((n_times - pool1_stride) // pool1_stride + 1) - pool2_stride) // pool2_stride + 1)\n",
    "\n",
    "        self.feature_extraction = nn.Sequential(\n",
    "            FeatureExtraction(n_channels=n_channels, kernel_length=kernel_length, F1=F1, D=D, F2=F2, pool1_stride=pool1_stride, pool2_stride=pool2_stride),\n",
    "            nn.Linear(in_features=self.feature_extraction_output, out_features=n_hidden),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "\n",
    "        self.transformer = nn.Sequential(\n",
    "            MyViTransformerWrapper(\n",
    "                image_size = n_times,\n",
    "                patch_size = patches_size,\n",
    "                channels=n_channels,\n",
    "                attn_layers = Encoder(\n",
    "                    dim = transformer_ffd,\n",
    "                    depth = transformer_layers,\n",
    "                    heads = transformer_heads\n",
    "                )\n",
    "            ),\n",
    "            nn.Linear(in_features=transformer_ffd, out_features=n_hidden),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "        )\n",
    "\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(in_features=n_hidden*2, out_features=n_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, targets):\n",
    "        out_values = {}\n",
    "        feature_extraction_result = self.feature_extraction(x)\n",
    "        transformer_result = self.transformer(x)\n",
    "        logits = self.head(torch.cat([\n",
    "            feature_extraction_result,\n",
    "            transformer_result\n",
    "        ], dim=-1))\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss, out_values"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#data augmentation\n",
    "from braindecode.augmentation import FrequencyShift\n",
    "from braindecode.augmentation import GaussianNoise\n",
    "\n",
    "sfreq = epochs.info['sfreq']\n",
    "\n",
    "freq_shift = FrequencyShift(\n",
    "    probability=0.5,  # defines the probability of actually modifying the input\n",
    "    sfreq=sfreq,\n",
    "    max_delta_freq=2.  # the frequency shifts are sampled now between -2 and 2 Hz\n",
    ")\n",
    "\n",
    "gauss_noise = GaussianNoise(\n",
    "    probability=0.5,\n",
    "    std=0.01\n",
    ")\n",
    "\n",
    "transforms = {\n",
    "    'freq': freq_shift,\n",
    "    'gauss': gauss_noise\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data = epochs.get_data()\n",
    "X = torch.tensor(data).to(dtype=torch.float32, device=device)\n",
    "y = torch.tensor(labels).to(dtype=torch.long, device=device)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = EEGNET(n_times=X.shape[-1], n_channels=len(epochs.picks), n_classes=len(set(labels)))\n",
    "model = model.to(device=device)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "seed = 1330\n",
    "splits = 5\n",
    "lr=3e-3\n",
    "\n",
    "skf = StratifiedKFold(n_splits=splits, random_state=seed, shuffle=True)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=0.3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1211,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_37344\\588025247.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      8\u001B[0m     \u001B[0my_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_test\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mtrain_index\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mtest_index\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 10\u001B[1;33m     \u001B[0mTrainerTester\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtrain_loop\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0moptimizer\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mX_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mX_test\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_test\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlr\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mud\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbatch_size\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m16\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0miterations\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m2000\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     11\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     12\u001B[0m     \u001B[0mout_values\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mTrainerTester\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtest_loop\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mX_test\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_test\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Desktop\\datspell\\eegnet-testing\\modules\\TrainTester.py\u001B[0m in \u001B[0;36mtrain_loop\u001B[1;34m(model, optimizer, X_train, y_train, X_test, y_test, lr, ud, batch_size, iterations)\u001B[0m\n\u001B[0;32m     35\u001B[0m             \u001B[1;31m# Backpropagation\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     36\u001B[0m             \u001B[0moptimizer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mzero_grad\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 37\u001B[1;33m             \u001B[0mloss\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     38\u001B[0m             \u001B[0moptimizer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstep\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     39\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\torch\\_tensor.py\u001B[0m in \u001B[0;36mbackward\u001B[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[0;32m    486\u001B[0m                 \u001B[0minputs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0minputs\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    487\u001B[0m             )\n\u001B[1;32m--> 488\u001B[1;33m         torch.autograd.backward(\n\u001B[0m\u001B[0;32m    489\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mgradient\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mretain_graph\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0minputs\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    490\u001B[0m         )\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001B[0m in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[0;32m    195\u001B[0m     \u001B[1;31m# some Python versions print out the first line of a multi-line function\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    196\u001B[0m     \u001B[1;31m# calls in the traceback and some print out the last line\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 197\u001B[1;33m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001B[0m\u001B[0;32m    198\u001B[0m         \u001B[0mtensors\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mgrad_tensors_\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mretain_graph\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcreate_graph\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    199\u001B[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from modules.TrainTester import TrainerTester\n",
    "\n",
    "ud = []\n",
    "\n",
    "#main-trianing-loop\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X[train_index], X[test_index],\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    TrainerTester.train_loop(model, optimizer, X_train, y_train, X_test, y_test, lr, ud, batch_size=16, iterations=2000)\n",
    "\n",
    "    out_values = TrainerTester.test_loop(model, X_test, y_test)\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#params evaluation\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, np.prod(param.size()))\n",
    "\n",
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "print('total: ', params)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def unison_shuffled_copies(a, b):\n",
    "    assert len(a) == len(b)\n",
    "    p = np.random.permutation(len(a))\n",
    "    return a[p], b[p]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "meta_step_size = 0.25\n",
    "\n",
    "meta_iters = 1000\n",
    "\n",
    "eval_interval = 1\n",
    "train_shots = 40\n",
    "eval_shots = 4\n",
    "classes = len(set(labels))\n",
    "\n",
    "batch_size = 1\n",
    "#obs: total shots = classes * shots\n",
    "\n",
    "n_times=X.shape[-1]\n",
    "n_channels=len(epochs.picks)\n",
    "\n",
    "seed = 1330\n",
    "splits = 5\n",
    "lr=1e-3\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, random_state=seed, shuffle=True)\n",
    "\n",
    "train_index, test_index = skf.split(X, y).__next__()\n",
    "X_train, X_test = X[train_index], X[test_index],\n",
    "y_train, y_test = y[train_index], y[test_index]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, training):\n",
    "        split = \"train\" if training else \"test\"\n",
    "\n",
    "        if split:\n",
    "            X_dataset, y_dataset = X_test, y_test\n",
    "        else:\n",
    "            X_dataset, y_dataset = X_train, y_train\n",
    "\n",
    "        self.data = {}\n",
    "\n",
    "        for value, label in zip(X_dataset, y_dataset):\n",
    "            if label not in self.data:\n",
    "                self.data[label] = []\n",
    "            self.data[label].append(value)\n",
    "        self.labels = list(self.data.keys())\n",
    "\n",
    "    def get_mini_dataset(self, shots, num_classes, split=False):\n",
    "        temp_labels = torch.zeros((num_classes * shots))\n",
    "        temp_X = torch.zeros((num_classes * shots, n_channels, n_times))\n",
    "        if split:\n",
    "            test_labels = torch.zeros((num_classes * eval_shots))\n",
    "            test_X = torch.zeros((num_classes * eval_shots, n_channels, n_times))\n",
    "\n",
    "        # Get a random subset of labels from the entire label set.\n",
    "        label_subset = random.choices(self.labels, k=num_classes)\n",
    "        for class_idx, class_obj in enumerate(label_subset):\n",
    "            # Use enumerated index value as a temporary label for mini-batch in\n",
    "            # few shot learning.\n",
    "            temp_labels[class_idx * shots : (class_idx + 1) * shots] = class_idx\n",
    "            # If creating a split dataset for testing, select an extra sample from each\n",
    "            # label to create the test dataset.\n",
    "            if split:\n",
    "                test_labels[class_idx] = class_idx\n",
    "                X_to_split = torch.stack(random.choices(self.data[label_subset[class_idx]], k=shots + 1))\n",
    "                test_X[class_idx] = X_to_split[-1]\n",
    "                temp_X[class_idx * shots : (class_idx + 1) * shots] = X_to_split[:-1]\n",
    "            else:\n",
    "                # For each index in the randomly selected label_subset, sample the\n",
    "                # necessary number of images.\n",
    "                temp_X[class_idx * shots : (class_idx + 1) * shots] = \\\n",
    "                    torch.stack(random.choices(self.data[label_subset[class_idx]], k=shots))\n",
    "\n",
    "        temp_X, temp_labels = unison_shuffled_copies(temp_X, temp_labels)\n",
    "        temp_X, temp_labels = torch.stack(temp_X.chunk(batch_size)), torch.stack(temp_labels.chunk(batch_size))\n",
    "        dataset = zip(temp_X, temp_labels)\n",
    "\n",
    "        if split:\n",
    "            test_X, test_labels = unison_shuffled_copies( test_X, test_labels)\n",
    "            return dataset, test_X, test_labels\n",
    "        return dataset\n",
    "\n",
    "train_dataset = Dataset(training=True)\n",
    "test_dataset = Dataset(training=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "training = []\n",
    "testing = []\n",
    "for meta_iter in range(meta_iters):\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "    frac_done = meta_iter / meta_iters\n",
    "\n",
    "    cur_meta_step_size = (1 - frac_done) * meta_step_size\n",
    "\n",
    "    old_vars = model.state_dict()\n",
    "\n",
    "    mini_dataset = train_dataset.get_mini_dataset(\n",
    "        train_shots, classes\n",
    "    )\n",
    "\n",
    "    for X_values, y_labels in mini_dataset:\n",
    "        y_labels = y_labels.to(dtype=torch.long)\n",
    "        preds, loss, out_values = model(X_values, y_labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    new_vars = model.state_dict()\n",
    "\n",
    "    for key, var in new_vars.items():\n",
    "        new_vars[key] = old_vars[key] + ((new_vars[key] - old_vars[key]) * 0.1)\n",
    "\n",
    "    model.load_state_dict(new_vars)\n",
    "\n",
    "    # Evaluation loop\n",
    "    if meta_iter % eval_interval == 0:\n",
    "        accuracies = []\n",
    "        for dataset in (train_dataset, test_dataset):\n",
    "            # print(\"test dataset reset!\\n\")\n",
    "            # Sample a mini dataset from the full dataset.\n",
    "            train_set, test_X, test_labels = dataset.get_mini_dataset(\n",
    "                eval_shots, classes, split=True\n",
    "            )\n",
    "            old_vars = model.state_dict()\n",
    "\n",
    "            for X_values, y_labels in train_set:\n",
    "                y_labels = y_labels.to(dtype=torch.long)\n",
    "\n",
    "                preds, test_loss, out_values = model(X_values, y_labels)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                test_loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            test_labels = test_labels.to(dtype=torch.long)\n",
    "            test_preds, test_loss, test_out_values = model(test_X, test_labels)\n",
    "\n",
    "            accuracy = (test_preds.argmax(1) == test_labels).type(torch.float32).sum().item() / test_labels.shape[0]\n",
    "            accuracies.append(accuracy)\n",
    "\n",
    "            model.load_state_dict(old_vars)\n",
    "\n",
    "        training.append(accuracies[0])\n",
    "        testing.append(accuracies[1])\n",
    "\n",
    "        if meta_iter % 100 == 0:\n",
    "            print(f\"batch {meta_iter}: train={accuracies[0]} test={accuracies[1]}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# First, some preprocessing to smooth the training and testing arrays for display.\n",
    "window_length = 100\n",
    "train_s = np.r_[\n",
    "    training[window_length - 1 : 0 : -1], training, training[-1:-window_length:-1]\n",
    "]\n",
    "test_s = np.r_[\n",
    "    testing[window_length - 1 : 0 : -1], testing, testing[-1:-window_length:-1]\n",
    "]\n",
    "w = np.hamming(window_length)\n",
    "train_y = np.convolve(w / w.sum(), train_s, mode=\"valid\")\n",
    "test_y = np.convolve(w / w.sum(), test_s, mode=\"valid\")\n",
    "\n",
    "# Display the training accuracies.\n",
    "x = np.arange(0, len(test_y), 1)\n",
    "plt.plot(x, test_y, x, train_y)\n",
    "plt.legend([\"test\", \"train\"])\n",
    "plt.grid()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load('model_states/test_model_states.txt'))\n",
    "# torch.save(model.state_dict(), 'model_states/test_model_states.txt')"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
