{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import sys\n",
    "import random\n",
    "\n",
    "import mne\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import math\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "import importlib\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
    "%matplotlib inline"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def extract_image_patches(x, kernel, stride=1, dilation=1):\n",
    "    # Do TF 'SAME' Padding\n",
    "    b,c,h,w = x.shape\n",
    "    h2 = math.ceil(h / stride)\n",
    "    w2 = math.ceil(w / stride)\n",
    "    pad_row = (h2 - 1) * stride + (kernel - 1) * dilation + 1 - h\n",
    "    pad_col = (w2 - 1) * stride + (kernel - 1) * dilation + 1 - w\n",
    "    x = F.pad(x, (pad_row//2, pad_row - pad_row//2, pad_col//2, pad_col - pad_col//2))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from modules.BciDataHandler import BciDataHandler\n",
    "\n",
    "data_handler = BciDataHandler()\n",
    "data_handler.instantiate_dataset()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ------------------------------ bci competition dataset ------------------------------\n",
    "all_subject_epochs = mne.concatenate_epochs(list(data_handler.subjects_epochs.values()))\n",
    "all_labels = all_subject_epochs.events[:, -1] - 1\n",
    "\n",
    "# epochs = data_handler.subjects_epochs[1]\n",
    "# labels = np.array(data_handler.subjects_labels[1]) - 1\n",
    "\n",
    "epochs = data_handler.subjects_epochs[1]\n",
    "labels = np.array(data_handler.subjects_labels[1]) - 1\n",
    "labels"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# -------------------------------- ufjf dataset --------------------------------------\n",
    "# from modules.EdfHandler import EdfHandler\n",
    "#\n",
    "# epochs, labels = EdfHandler.getAllData([\"C:\\\\Users\\\\davi2\\Desktop\\\\bci\\\\datasets_ufjf\\\\bci\\\\001.edf\"])\n",
    "# epochs = epochs[0]\n",
    "# labels = np.array(labels[0])\n",
    "# labels[labels == 6] = 0"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#----------------------- physionet dataset -------------------------------------\n",
    "# import mne\n",
    "# from mne import Epochs, pick_types, events_from_annotations\n",
    "# from mne.channels import make_standard_montage\n",
    "# from mne.io import concatenate_raws, read_raw_edf\n",
    "# from mne.datasets import eegbci\n",
    "\n",
    "\n",
    "# #############################################################################\n",
    "# # Set parameters and read data\n",
    "\n",
    "# avoid classification of evoked responses by using epochs that start 1s after\n",
    "# cue onset.\n",
    "# tmin, tmax = -1., 4.\n",
    "# event_id = dict(handsOrLeft=2, feetOrRight=3)\n",
    "#\n",
    "# def get_physionet_data(subject, runs):\n",
    "#\n",
    "#     raw_fnames = eegbci.load_data(subject, runs)\n",
    "#     raw = concatenate_raws([read_raw_edf(f, preload=True) for f in raw_fnames])\n",
    "#     eegbci.standardize(raw)  # set channel names\n",
    "#     montage = make_standard_montage('standard_1005')\n",
    "#     raw.set_montage(montage)\n",
    "#\n",
    "#     # Apply band-pass filter\n",
    "#     raw.filter(7., 30., fir_design='firwin', skip_by_annotation='edge')\n",
    "#\n",
    "#     events, _ = events_from_annotations(raw)\n",
    "#\n",
    "#     picks = pick_types(raw.info, meg=False, eeg=True, stim=False, eog=False,\n",
    "#                        exclude='bads')\n",
    "#\n",
    "#     # Read epochs (train will be done only between 1 and 2s)\n",
    "#     # Testing will be done with a running classifier\n",
    "#     epochs = Epochs(raw, events, event_id, tmin, tmax, proj=True, picks=picks,\n",
    "#                     baseline=None, preload=True)\n",
    "#\n",
    "#     epochs_data = epochs.copy().crop(tmin=1., tmax=2.)\n",
    "#\n",
    "#     labels = epochs.events[:, -1] - 2\n",
    "#\n",
    "#     return epochs_data, labels\n",
    "\n",
    "\n",
    "# [6, 10, 14] hands vs feet\n",
    "#[4, 8, 12] left vs right hand\n",
    "# X_hf, y_hf = get_physionet_data(subject=1, runs=[6, 10, 14])\n",
    "# X_lr, y_lr = get_physionet_data(subject=1, runs=[4, 8, 12])\n",
    "#\n",
    "# epochs = mne.concatenate_epochs([X_hf, X_lr])\n",
    "# labels = np.concatenate([y_hf, y_lr+2])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# def plot_psd(data, axis, label, color):\n",
    "#     psds, freqs = mne.time_frequency.psd_array_multitaper(data, sfreq=sfreq,\n",
    "#                                                           fmin=0.1, fmax=100)\n",
    "#     psds = 10. * np.log10(psds)\n",
    "#     psds_mean = psds.mean(0).mean(0)\n",
    "#     axis.plot(freqs, psds_mean, color=color, label=label)\n",
    "#\n",
    "#\n",
    "# _, ax = plt.subplots()\n",
    "# plot_psd(X, ax, 'original', 'k')\n",
    "# plot_psd(X_tr.numpy(), ax, 'shifted', 'r')\n",
    "#\n",
    "# ax.set(title='Multitaper PSD (gradiometers)', xlabel='Frequency (Hz)',\n",
    "#        ylabel='Power Spectral Density (dB)')\n",
    "# ax.legend()\n",
    "# plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from Models.SubModules import ViewConv, DepthWiseConv2d, SeparableConv2d, Unsqueeze, PositionalEncoding, ToTransformer, \\\n",
    "    MaxNormLayer, FeatureExtraction, EmbeddingLayer, VisionTransformer\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class EEGNET(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            n_times,\n",
    "            n_classes,\n",
    "            n_channels,\n",
    "            patches=32,\n",
    "            embedding_dim=16,\n",
    "            dropout_rate=0.1,\n",
    "            transformer_ffd=128,\n",
    "            max_norm=0.25,\n",
    "            F1=8,\n",
    "            F2=16,\n",
    "            D=2,\n",
    "            pool1_stride=4,\n",
    "            pool2_stride=8,\n",
    "            kernel_length=64,\n",
    "            channel_depht=1\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.feature_extraction_output = F2 * ((((n_times - pool1_stride) // pool1_stride + 1) - pool2_stride) // pool2_stride + 1)\n",
    "\n",
    "        self.feature_extraction = FeatureExtraction(n_channels=n_channels, kernel_length=kernel_length, F1=F1, D=D, F2=F2, pool1_stride=pool1_stride, pool2_stride=pool2_stride)\n",
    "\n",
    "        self.embedding = EmbeddingLayer(n_times=self.feature_extraction_output, patches_num=patches, embedding_dim=embedding_dim, dropout_rate=dropout_rate)\n",
    "\n",
    "        self.transformer = VisionTransformer(patches=patches, transformer_ffd=transformer_ffd)\n",
    "\n",
    "        # self.conv_simplifier = ConvolutionSimplifier(embedding_dim=embedding_dim, dropout_rate=dropout_rate)\n",
    "\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(in_features=patches, out_features=1),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.ELU(),\n",
    "            nn.Flatten(),\n",
    "            MaxNormLayer(in_features=embedding_dim, out_features=n_classes, max_norm=max_norm),\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x, targets):\n",
    "        out_values = {}\n",
    "        out = self.feature_extraction(x)\n",
    "        out = self.embedding(out)\n",
    "        out = self.transformer(out)\n",
    "        # out = self.conv_simplifier(out)\n",
    "        logits = self.head(out)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss, out_values"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X = torch.tensor(epochs.get_data()).to(dtype=torch.float32, device=device)\n",
    "y = torch.tensor(labels).to(dtype=torch.long, device=device)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = EEGNET(n_times=X.shape[-1], n_channels=len(epochs.picks), n_classes=4)\n",
    "model = model.to(device=device)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#data augmentation\n",
    "from braindecode.augmentation import FrequencyShift\n",
    "from braindecode.augmentation import GaussianNoise\n",
    "\n",
    "sfreq = epochs.info['sfreq']\n",
    "\n",
    "freq_shift = FrequencyShift(\n",
    "    probability=0.5,  # defines the probability of actually modifying the input\n",
    "    sfreq=sfreq,\n",
    "    max_delta_freq=2.  # the frequency shifts are sampled now between -2 and 2 Hz\n",
    ")\n",
    "\n",
    "gauss_noise = GaussianNoise(\n",
    "    probability=0.5,\n",
    "    std=0.01\n",
    ")\n",
    "\n",
    "transforms = {\n",
    "    'freq': freq_shift,\n",
    "    'gauss': gauss_noise\n",
    "}\n",
    "\n",
    "X_tr, _ = freq_shift.operation(X, None, 10., sfreq)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "seed = 1330\n",
    "splits = 5\n",
    "lr=3e-3\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, random_state=seed, shuffle=True)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=0.3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from modules.TrainTester import TrainerTester\n",
    "\n",
    "ud = []\n",
    "\n",
    "#main-trianing-loop\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    X_train, X_test = X[train_index], X[test_index],\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    TrainerTester.train_loop(model, optimizer, X_train, y_train, X_test, y_test, lr, ud, batch_size=32, iterations=2000)\n",
    "\n",
    "    out_values = TrainerTester.test_loop(model, X_test, y_test)\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#params evaluation\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, np.prod(param.size()))\n",
    "\n",
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "print('total: ', params)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "legends = []\n",
    "i = 0\n",
    "for name, p in model.named_parameters():\n",
    "    plt.plot([ud[j][i] for j in range(len(ud))])\n",
    "    legends.append(name)\n",
    "    i += 1\n",
    "plt.plot([0, len(ud)], [-3, -3], 'k') # these ratios should be ~1e-3, indicate on plot\n",
    "plt.legend(legends);"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# visualize histograms\n",
    "plt.figure(figsize=(40, 30)) # width and height of the plot\n",
    "legends = []\n",
    "for name, values in out_values.items(): # note: exclude the output value\n",
    "    if name != \"Softmax\":\n",
    "        t = values\n",
    "        print(f'{name}: mean {t.mean()}, std {t.std()}')\n",
    "        hy, hx = torch.histogram(t, density=True)\n",
    "        plt.plot(hx[:-1].detach(), hy.detach())\n",
    "        legends.append(f'layer ({name}')\n",
    "plt.legend(legends)\n",
    "plt.title('gradient distribution')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import re\n",
    "# visualize histograms\n",
    "plt.figure(figsize=(40, 20)) # width and height of the plot\n",
    "legends = []\n",
    "for name, params in model.named_parameters():\n",
    "    if not re.search('bias', name):\n",
    "        t = params.grad\n",
    "        print(f'layer {name}: weight {tuple(params.shape)} | mean {t.mean()} | std {t.std()} | grad:data ratio { t.std() / params.std()}')\n",
    "        hy, hx = torch.histogram(t, density=True)\n",
    "        plt.plot(hx[:-1].detach(), hy.detach())\n",
    "        legends.append(f'{name} {tuple(params.shape)}')\n",
    "plt.legend(legends)\n",
    "plt.title('weights gradient distribution');"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import re\n",
    "# visualize histograms\n",
    "plt.figure(figsize=(20, 10)) # width and height of the plot\n",
    "legends = []\n",
    "for name, params in model.named_parameters():\n",
    "    if not re.search('bias', name) and not re.search('norm', name):\n",
    "        t = params\n",
    "        print(f'layer {name}: weight {tuple(params.shape)} | mean {t.mean()} | std {t.std()} | weight:data ratio { t.std() / params.std()}')\n",
    "        hy, hx = torch.histogram(t, density=True)\n",
    "        plt.plot(hx[:-1].detach(), hy.detach())\n",
    "        legends.append(f'{name} {tuple(params.shape)}')\n",
    "plt.legend(legends)\n",
    "plt.title('weights distribution');"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load('model_states/test_model_states.txt'))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), 'model_states/test_model_states.txt')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
