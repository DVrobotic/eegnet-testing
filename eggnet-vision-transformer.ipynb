{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import sys\n",
    "import random\n",
    "\n",
    "import mne\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import math\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "import importlib\n",
    "from einops import rearrange, reduce, repeat\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
    "%matplotlib inline"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ------------------------------ bci competition dataset ------------------------------\n",
    "from moabb.datasets import BNCI2014001\n",
    "from moabb.paradigms import MotorImagery\n",
    "# fmin = 4\n",
    "# fmax = 100\n",
    "fmin = 5\n",
    "fmax = 60\n",
    "tmin = 0\n",
    "tmax = None\n",
    "\n",
    "X_list = []\n",
    "y_list = []\n",
    "\n",
    "# Load the dataset\n",
    "subjects = [1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "for subject in subjects:\n",
    "    dataset = BNCI2014001()\n",
    "    events = ['left_hand', 'right_hand', 'feet', 'tongue']\n",
    "    labels_to_int = {'left_hand':0, 'right_hand':1, 'feet':2, 'tongue':3}\n",
    "    paradigm = MotorImagery(\n",
    "        events=events, n_classes=len(events), fmin=fmin, fmax=fmax, tmin=tmin, tmax=tmax\n",
    "    )\n",
    "\n",
    "    data, labels, _ = paradigm.get_data(dataset=dataset, subjects=[subject])\n",
    "    data = data[:, :, :500]\n",
    "\n",
    "    labels = [labels_to_int[label] for label in labels]\n",
    "\n",
    "    X_list.append(torch.tensor(data).to(dtype=torch.float32, device=device))\n",
    "    y_list.append(torch.tensor(labels).to(dtype=torch.long, device=device))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from Models.FinalModels import Eegnet, EegnetTemporal, EegnetSpatial, EegnetTemporalSpatial\n",
    "\n",
    "#tests info\n",
    "channels = 22\n",
    "classes = 4\n",
    "samples=500\n",
    "frequency=250\n",
    "kernel_length = frequency//2\n",
    "seed = 1330\n",
    "models = [\n",
    "    'eegnet',\n",
    "    'eegnet + temporal',\n",
    "    'eegnet + spatial',\n",
    "    'eegnet + spatial + temporal'\n",
    "]\n",
    "\n",
    "def getModel(name):\n",
    "    if name == 'eegnet':\n",
    "        return Eegnet(n_times=samples, n_channels=channels, n_classes=classes, kernel_length=kernel_length)\n",
    "\n",
    "    if name == 'eegnet + temporal':\n",
    "        return EegnetTemporal(n_times=samples, n_channels=channels, n_classes=classes, kernel_length=kernel_length)\n",
    "\n",
    "    if name == 'eegnet + spatial':\n",
    "        return EegnetSpatial(n_times=samples, n_channels=channels, n_classes=classes, kernel_length=kernel_length)\n",
    "\n",
    "    if name == 'eegnet + spatial + temporal':\n",
    "        return EegnetTemporalSpatial(n_times=samples, n_channels=channels, n_classes=classes, kernel_length=kernel_length)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ------------------------------ bci competition dataset ------------------------------\n",
    "from moabb.datasets import BNCI2014001\n",
    "from moabb.paradigms import MotorImagery\n",
    "# fmin = 4\n",
    "# fmax = 100\n",
    "fmin = 5\n",
    "fmax = 60\n",
    "tmin = 0\n",
    "tmax = None\n",
    "\n",
    "X_list = []\n",
    "y_list = []\n",
    "\n",
    "# Load the dataset\n",
    "subjects = [1]\n",
    "dataset = BNCI2014001()\n",
    "events = ['left_hand', 'right_hand', 'feet', 'tongue']\n",
    "labels_to_int = {'left_hand':0, 'right_hand':1, 'feet':2, 'tongue':3}\n",
    "paradigm = MotorImagery(\n",
    "    events=events, n_classes=len(events), fmin=fmin, fmax=fmax, tmin=tmin, tmax=tmax\n",
    ")\n",
    "\n",
    "data, labels, _ = paradigm.get_data(dataset=dataset, subjects=subjects)\n",
    "data = data[:, :, :500]\n",
    "\n",
    "labels = [labels_to_int[label] for label in labels]\n",
    "\n",
    "X = torch.tensor(data).to(dtype=torch.float32, device=device)\n",
    "y = torch.tensor(labels).to(dtype=torch.long, device=device)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from Models.FinalModels import exists\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from einops import rearrange, reduce, repeat\n",
    "from einops.layers.torch import Rearrange\n",
    "from x_transformers import Encoder\n",
    "\n",
    "from utils.utils import initialize_weight\n",
    "from base.layers import Conv2dWithConstraint\n",
    "\n",
    "\n",
    "class EegnetModified(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            n_channels,\n",
    "            kernel_length,\n",
    "            F1,\n",
    "            D,\n",
    "            F2,\n",
    "            pool1_stride,\n",
    "            pool2_stride,\n",
    "            dropout_rate,\n",
    "            weight_init_method=None\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        # Spectral\n",
    "        self.spectral = nn.Sequential(\n",
    "            Rearrange('b c w -> b 1 c w'),\n",
    "            nn.Conv2d(1, F1, (1, kernel_length), bias=False, padding='same'),\n",
    "            nn.BatchNorm2d(F1),\n",
    "        )\n",
    "\n",
    "        #residual spectral\n",
    "        self.residual_spc =  nn.Sequential(\n",
    "            Rearrange('b c w -> b 1 c w'),\n",
    "        )\n",
    "\n",
    "        # Spatial\n",
    "        self.spatial = nn.Sequential(\n",
    "            Conv2dWithConstraint(F1, F1 * D, (n_channels, 1), bias=False, groups=F1),\n",
    "            nn.BatchNorm2d(F1 * D),\n",
    "            nn.ELU(),\n",
    "            nn.AvgPool2d((1, pool1_stride)),\n",
    "            nn.Dropout(dropout_rate),\n",
    "        )\n",
    "\n",
    "        #residual Spatial\n",
    "        self.residual_spt = nn.Sequential(\n",
    "            nn.Conv2d(F1, F1 * D, (n_channels, 1), bias=False, groups=F1),\n",
    "            nn.ELU(),\n",
    "            nn.AvgPool2d((1, pool1_stride)),\n",
    "            nn.Dropout(dropout_rate),\n",
    "        )\n",
    "\n",
    "        # Temporal\n",
    "        self.temporal = nn.Sequential(\n",
    "            nn.Conv2d(F1 * D, F2, (1, n_channels), bias=False, padding='same', groups=F2),\n",
    "            nn.Conv2d(F2, F2, 1, bias=False),\n",
    "            nn.BatchNorm2d(F2),\n",
    "            nn.ELU(),\n",
    "            nn.AvgPool2d((1, pool2_stride)),\n",
    "            nn.Dropout(dropout_rate),\n",
    "        )\n",
    "\n",
    "        initialize_weight(self, weight_init_method)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #spectral\n",
    "        spc_out = self.spectral(x)\n",
    "        spc_residual = self.residual_spc(x)\n",
    "\n",
    "        # Spatial\n",
    "        spt_out = self.spatial(spc_out + spc_residual)\n",
    "        spt_residual = self.residual_spt(spc_out + spc_residual)\n",
    "\n",
    "        # Temporal\n",
    "        out = self.temporal(spt_out + spt_residual)\n",
    "\n",
    "        return out\n",
    "\n",
    "class AttnBlock(nn.Module):\n",
    "    def __init__(self, dim, nheads, dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.ffd1 = nn.Sequential(\n",
    "            nn.LayerNorm(dim),\n",
    "            nn.Linear(in_features=dim, out_features=dim),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "        self.attention1 = nn.MultiheadAttention(embed_dim=dim, num_heads=nheads, batch_first=True, dropout=dropout)\n",
    "\n",
    "        self.ff2 = nn.Sequential(\n",
    "            nn.LayerNorm(dim),\n",
    "            nn.Linear(in_features=dim, out_features=dim),\n",
    "            nn.ELU(),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b1_out = self.ffd1(x)\n",
    "        at1_out, attn_output_weights = self.attention1(b1_out, b1_out ,b1_out)\n",
    "        ffd1_out = self.ff2(at1_out + x)\n",
    "        return ffd1_out\n",
    "\n",
    "\n",
    "\n",
    "class SelfAttentionConv(nn.Module):\n",
    "    def __init__(self, n_channels):\n",
    "        super().__init__()\n",
    "        self.query,self.key,self.value = [self._conv(n_channels, c) for c in (n_channels//8,n_channels//8,n_channels)]\n",
    "        self.gamma = nn.Parameter(torch.tensor([0.]))\n",
    "\n",
    "    def _conv(self,n_in,n_out):\n",
    "        return nn.Conv1d(n_in, n_out, kernel_size=1, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #Notation from the paper.\n",
    "        size = x.size()\n",
    "        f,g,h = self.query(x), self.key(x), self.value(x)\n",
    "        beta = F.softmax(f.transpose(1,2) @ g, dim=1)\n",
    "        o = self.gamma * (h @ beta) + x\n",
    "        return o.view(*size).contiguous()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from Models.FinalModels import FeatureExtraction\n",
    "from x_transformers import Encoder, ContinuousTransformerWrapper\n",
    "\n",
    "\n",
    "class Temporal(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            n_times,\n",
    "            n_classes,\n",
    "            n_channels,\n",
    "            kernel_length,\n",
    "            dropout_rate=0.5,\n",
    "            F1=8,\n",
    "            F2=16,\n",
    "            D=2,\n",
    "            pool1_stride=16,\n",
    "            pool2_stride=8,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.feature_extraction_output = F2 * (\n",
    "                (((n_times - pool1_stride) // pool1_stride + 1) - pool2_stride) // pool2_stride + 1)\n",
    "\n",
    "        self.feature_extraction = nn.Sequential(\n",
    "            EegnetModified(n_channels=n_channels, kernel_length=kernel_length, F1=F1, D=D, F2=F2,\n",
    "                           pool1_stride=pool1_stride, pool2_stride=pool2_stride, dropout_rate=dropout_rate),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(in_features=self.feature_extraction_output, out_features=n_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, targets):\n",
    "        fe_out = self.feature_extraction(x)\n",
    "        logits = self.head(fe_out)\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "\n",
    "        return logits, loss, {}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = Temporal(n_times=samples, n_channels=channels, n_classes=classes, kernel_length=kernel_length)\n",
    "model = model.to(device=device)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#params evaluation\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, np.prod(param.size()))\n",
    "\n",
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "print('total: ', params)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from modules.TrainTester import TrainerTester\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, random_state=seed, shuffle=True)\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    optimizer = torch.optim.AdamW(model.parameters())\n",
    "\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    TrainerTester.train_loop(model, optimizer, X_train, y_train, X_test, y_test, 1, [], batch_size=32, iterations=2000)\n",
    "    loss, accuracy, kappa = TrainerTester.test_loss(model, X_test, y_test)\n",
    "    print(loss.item(), accuracy, kappa)\n",
    "    break\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# from modules.TrainTester import TrainerTester\n",
    "# import pandas as pd\n",
    "#\n",
    "#\n",
    "# dataframe_dict = {}\n",
    "# test = 0\n",
    "# for model_name in models:\n",
    "#     print(f\"iniciando treinamento da model {model_name}\")\n",
    "#     subject_counter = 1\n",
    "#     for X, y in zip(X_list, y_list):\n",
    "#         print(f\"iniciando teste de sujeito {subject_counter}\")\n",
    "#\n",
    "#         dataframe_dict[f\"{model_name} sujeito {subject_counter} kappa\"] = []\n",
    "#         dataframe_dict[f\"{model_name} sujeito {subject_counter} acc\"] = []\n",
    "#         dataframe_dict[f\"{model_name} sujeito {subject_counter} loss\"] = []\n",
    "#         for i in range(0, 5):\n",
    "#             print(f'iniciando 5k fold {i+1}/5')\n",
    "#\n",
    "#             skf = StratifiedKFold(n_splits=5, random_state=seed+i, shuffle=True)\n",
    "#             k_fold_counter = 0\n",
    "#             for train_index, test_index in skf.split(X, y):\n",
    "#                 model = getModel(model_name)\n",
    "#                 model = model.to(device=device)\n",
    "#                 optimizer = torch.optim.AdamW(model.parameters(), lr=8e-4)\n",
    "#\n",
    "#                 X_train, X_test = X[train_index], X[test_index]\n",
    "#                 y_train, y_test = y[train_index], y[test_index]\n",
    "#\n",
    "#                 TrainerTester.simplified_train_loop(model, optimizer, X_train, y_train, X_test, y_test, batch_size=32, iterations=2000)\n",
    "#\n",
    "#                 loss, accuracy, kappa = TrainerTester.test_loss(model, X_test, y_test)\n",
    "#                 print(f'{model_name} results in 5k fold {k_fold_counter}/5\\n kappa: {kappa}\\n accuracy: {accuracy}\\n loss: {loss}')\n",
    "#                 k_fold_counter += 1\n",
    "#\n",
    "#                 dataframe_dict[f\"{model_name} sujeito {subject_counter} kappa\"].append(kappa)\n",
    "#                 dataframe_dict[f\"{model_name} sujeito {subject_counter} acc\"].append(accuracy)\n",
    "#                 dataframe_dict[f\"{model_name} sujeito {subject_counter} loss\"].append(loss)\n",
    "#\n",
    "#         subject_counter += 1\n",
    "#         final_dataframe = pd.DataFrame.from_dict(dataframe_dict)\n",
    "#         final_dataframe.to_csv('resultados_paper.csv')\n",
    "#\n",
    "# final_dataframe = pd.DataFrame.from_dict(dataframe_dict)\n",
    "# final_dataframe.to_csv('resultados_paper.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
